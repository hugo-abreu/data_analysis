{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Analyse de Données\n",
    "\n",
    "## Analyse de Textes - Classification de l'auteur par stylométrie\n",
    "\n",
    "- Hugo Abreu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vais construire un système de reconnaissance de style d'écriture, qui - en lui donnant une base de données de textes - calcule des métriques de style (qui ont été montrées comme étant plus ou moins invariables selon l'auteur) et peut ensuite les utiliser pour entrainer un modèle qui permet de reconnaitre l'auteur d'un texte uniquement à partir du texte brut.\n",
    "\n",
    "Une première partie du travail concerne le traitement des textes et l'extraction des métriques de style.\n",
    "\n",
    "Ensuite, je vais transformer ces métriques dans un format utilisable par des algorithmes de classification.\n",
    "\n",
    "Finalement, je vais entrainer ces algorithmes de classification pour pouvoir tester leur performance sur des données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La stylométrie est un thème très abordé en linguistique, et beaucoup de personnes ont déjà créé des métriques qui ont été prouvées, sur un corpus de textes, comme étant propres à l'auteur. Je ne vais pas m'occuper de montrer en quoi mes métriques reflètent l'auteur, mais je me suis inspiré de certaines déjà existantes et je pense qu'elles ont du sens. \n",
    "\n",
    "Je me suis inspiré des papiers suivants pour construire mes métriques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Efstathios Stamatatos, “A Survey of Modern Authorship Attribution Method,” Journal of the American Society for Information Science and Technology, vol. 60, no. 3 (December 2008), p. 538–56, citation on p. 540, https://doi.org/10.1002/asi.21001.\n",
    "- Douglass Adair, “The Authorship of the Disputed Federalist Papers”, The William and Mary Quarterly, vol. 1, no. 2 (April 1944), pp. 97-122.\n",
    "- John Burrows, “All the Way Through: Testing for Authorship in Different Frequency Strata,” Literary and Linguistic Computing, vol. 22, no. 1 (April 2007), pp. 27–47, https://doi.org/10.1093/llc/fqi067.\n",
    "- John Burrows, “‘Delta’: a Measure of Stylistic Difference and a Guide to Likely Authorship”, Literary and Linguistic Computing, vol. 17, no. 3 (2002), pp. 267-287"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hpa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Librairies générales\n",
    "import os\n",
    "import numpy       as np\n",
    "import pandas      as pd\n",
    "import math\n",
    "import string\n",
    "import json\n",
    "import collections as col\n",
    "import time\n",
    "\n",
    "# Librairies Langage Naturelle\n",
    "import nltk\n",
    "from   nltk.corpus   import cmudict, stopwords\n",
    "from   nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Librairies d'analyse (Machine Learning)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors     import KNeighborsClassifier\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.metrics       import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Librairies visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de Données de Fichiers texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vais utiliser les textes qui se trouvent en http://textfiles.com/etext/AUTHORS/. Ils sont en format .txt et sont indexes par autheur. \n",
    "\n",
    "Comme le nom de chaque fichier commence par auteur-xxx.txt, je peut facilement récupérer l'auteur avec le nom du fichier.\n",
    "\n",
    "Quelques fichiers (ceux qui proviennent du projet Gutenberg) possèdent une grande entête. J'ai donc manuellement enlevé les entêtes pour ces fichiers, pour ne pas fausser les analyses de style\n",
    "\n",
    "J'ai préféré utiliser des textes en anglais, vu qu'il existe plus de métriques de style publiées en anglais, et que les librairies de langage naturel sont plus développées en anlais. De plus, il est plus facile d'obtenir des bases de données de textes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vais créer une classe document, qui gère la décomposition des textes et le calcul de métriques.\n",
    "\n",
    "Un objet de cette classe représente un texte, et possède les attributs suivants:\n",
    "- un nom de fichier (récupéré dans un répertoire avec tous les fichiers)\n",
    "- un nom d'auteur (première partie du nom de fichier, avant le premier \"-\")\n",
    "- l'intégralité du texte (long string qui contient tout le fichier)\n",
    "- une liste de phrases en minuscules (donnée par la librairie nltk)\n",
    "- une liste de mots en minuscules (donnée par nltk)\n",
    "- une liste de mots sans ponctuation\n",
    "- une liste de mots, sans ponctuation, sans chiffres et sans mots stop (mots très courants qui ne reflètent pas forcément le style de l'auteur)\n",
    "    - si néanmoins l'utilisation de mots stops est une partie importante du style de l'auteur, j'ai une métrique qui me donne la proportion de mots stop dans tous les autres mots\n",
    "- un dictionnaire donnant l'occurence de chaque mot dans le texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important d'avoir des listes de mots sans les stopwords, vu que les stopwords sont nécessaires à la construction de phrases et ne révèlent pas forcément le style de l'auteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs précédants ne donnent pas d'information particulière sur le style de l'auteur, ils sont simplement des outils utiles pour pouvoir calculer des métriques. Je vais calculer des métriques à l'aide de ces attributs\n",
    "\n",
    "Je vais créer une méthode de classe `_stylographie()` qui appellera les fonctions calculant ces métriques, plus tard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition de métriques pour la stylométrie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len_moy_mots`: prend en paramètre la liste de mots sans points, chiffres, mots vides et mots stop, et renvoit:\n",
    "- la taille moyenne des mots dans le texte\n",
    "- la proportion de mots de taille supérieure à 10 caractères dans le texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def len_moy_mots(mots):\n",
    "    liste_len_mots = [len(mot) for mot in mots]\n",
    "    freq_dist = nltk.FreqDist(liste_len_mots)\n",
    "\n",
    "    prop_mots_superieurs_a_10 = 0\n",
    "    for val, nb_mots in list(filter(lambda x: x[1]>=1000, freq_dist.items())):\n",
    "        prop_mots_superieurs_a_10 += nb_mots\n",
    "\n",
    "    return np.average(liste_len_mots), (prop_mots_superieurs_a_10 / len(mots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len_moy_phrase_mots`: prend en paramètre la liste des phrases, et renvoit:\n",
    "- la taille moyenne des phrases selon le nombre de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def len_moy_phrase_mots(phrases):\n",
    "    return np.average([len(phrase.split()) for phrase in phrases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len_moy_phrase_caracteres`: prend en paramètre la liste des phrases, et renvoit:\n",
    "- la taille moyenne des phrases selon le nombre de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def len_moy_phrase_caracteres(phrases):\n",
    "    return np.average([len(phrase) for phrase in phrases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ponctuation`: prend en argument l'intégralité du document, et renvoit:\n",
    "- la liste d'occurences de chaque caractère appartenant à la liste de ponctuation de la librairie string (`string.punctuation`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def ponctuation(document):\n",
    "    return col.Counter([carac for carac in document if carac in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nb_moy_syllabes_mots`: prend en arguement la liste de mots sans points, chiffre, mots vides et mots stop, et renvoit:\n",
    "- le nombre moyen de syllabes par mot dans le texte, ne prenant pas en compte les mots stop (donc correlation avec le style de l'auteur)\n",
    "\n",
    "note: pour calculer le nombre de syllabes, je calcule combien de fois il y a une transition entre une voyelle et une autre lettre, dans un mot. Pour ce faire, j'ai créé une fonction `nb_syllabes()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def nb_moy_syllabes_mots(mots):\n",
    "\n",
    "    def nb_syllabes(mot):       # Fonction retournant le nb de syllabes dans un mot\n",
    "        return sum(list(map(lambda x:\n",
    "                            1 if x in [\"a\",\"e\",\"i\",\"o\",\"u\",\"y\",\"A\",\"E\",\"I\",\"O\",\"U\",\"Y\"]\n",
    "                            else 0, mot)))\n",
    "\n",
    "    return (sum([nb_syllabes(mot) for mot in mots]) / len(mots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`proportion_stop`: prend en argument la liste de mots, et la liste de mots sans points, chiffres, mots vides et mots stop, et renvoit:\n",
    "- proportion de mots stop dans mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def proportion_stop(mots,stop):\n",
    "    return len(stop)/len(mots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hapax_legomenon`: prend en argument la liste de mots sans points, chiffre, mots vides et mots stop, et renvoit:\n",
    "- proportion de mots ayant une occurance unique dans le texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def hapax_legomenon(mots):\n",
    "    occurences = col.Counter(mots)\n",
    "    unique = 0\n",
    "\n",
    "    for mot in occurences.keys():\n",
    "        if occurences[mot] == 1:\n",
    "            unique += 1\n",
    "\n",
    "    return unique / len(mots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test_flesh_kincaid`: prend en argument la liste de mots sans points, chiffre, mots vides ou mots stop, la liste de phrases, et le nombre moyen de syllabes par mot, et renvoit:\n",
    "- score du test de lisibilité Flesh Kincaid, un standard dans le milieu de stylométrie. Même si ce n'est qu'une combinaison de paramètres déjà calculés, il peut être utile pour analyser chaque texte individuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def test_flesh_kincaid(mots, phrases, nb_moy_syllabes_mots):\n",
    "    return 0.39 * (len(mots) / len(phrases)) + 11.8 * (nb_moy_syllabes_mots) - 15.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Déclaration de la classe Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On déclare la classe `Document` comme décrite précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Document(object):\n",
    "\n",
    "    def __init__(self, fichier):  # \n",
    "        print(\"initialisation de\", fichier)\n",
    "\n",
    "        self.fichier                   = fichier\n",
    "        self.auteur                    = fichier.split(\"-\")[0]\n",
    "        self.document                  = open(fichier, \"r\").read()\n",
    "        self.phrases                   = [x.lower() for x in sent_tokenize(self.document)]\n",
    "        self.mots                      = [x.lower() for x in word_tokenize(self.document)]\n",
    "\n",
    "        # Liste de mots, sans ponctuation et sans le mot vide\n",
    "        self.mots_sans_punct           = [mot.translate(str.maketrans('', '', string.punctuation))\n",
    "                                          for mot in self.mots\n",
    "                                          if  mot.translate(str.maketrans('', '', string.punctuation))]\n",
    "\n",
    "        # Liste de mots sans ponctuation, le mot vide, chiffre, ou mots stop\n",
    "        self.mots_sans_punct_chif_stop = [mot for mot in self.mots_sans_punct\n",
    "                                          if mot not in stopwords.words('english')\n",
    "                                          if not any(map(str.isdigit, mot))]\n",
    "\n",
    "        # Fréquence de chaque mot dans le texte\n",
    "        self.freq_occurences           = nltk.FreqDist(self.mots_sans_punct_chif_stop)\n",
    "\n",
    "        print(\"texte\", self.fichier, \"initialisé\")\n",
    "\n",
    "    def _stylographie(self):\n",
    "        # Critères lexicaux\n",
    "        self.len_moy_mots              = len_moy_mots(self.mots_sans_punct_chif_stop)\n",
    "        self.len_moy_phrase_mots       = len_moy_phrase_mots(self.phrases)\n",
    "        self.len_moy_phrase_caracteres = len_moy_phrase_caracteres(self.phrases)\n",
    "        self.ponctuation               = ponctuation(self.document)\n",
    "        self.nb_moy_syllabes_mots      = nb_moy_syllabes_mots(self.mots_sans_punct_chif_stop)\n",
    "        self.proportion_stop           = proportion_stop(self.mots, self.mots_sans_punct_chif_stop)\n",
    "\n",
    "        # Critères de richesse de vocabulaire\n",
    "        self.hapax_legomenon           = hapax_legomenon(self.mots_sans_punct_chif_stop)\n",
    "\n",
    "        # Scores de lisibilité\n",
    "        self.test_flesh_kincaid        = test_flesh_kincaid(self.mots, self.phrases, self.nb_moy_syllabes_mots)\n",
    "\n",
    "\n",
    "        print(\"métriques de\", self.fichier, \"calculées\")\n",
    "\n",
    "    def _print_stylographie(self):\n",
    "        # utile pour le debuggage ou pour analser un texte en particulier\n",
    "        print(\"len_moy_mots: \", self.len_moy_mots)\n",
    "        print(\"len_moy_phrase_mots: \", self.len_moy_phrase_mots)\n",
    "        print(\"len_moy_phrase_caracteres: \", self.len_moy_phrase_caracteres)\n",
    "        print(\"ponctuation: \", self.ponctuation)\n",
    "        print(\"nb_moyen_syllabes_mots: \", self.nb_moy_syllabes_mots)\n",
    "        print(\"proportion_stop: \", self.proportion_stop)\n",
    "        print(\"hapax: \", self.hapax_legomenon)\n",
    "        print(\"test_flesh_kincaid: \", self.test_flesh_kincaid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation des fichiers et calculs stylométriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour créer une base de donnée de documents, j'utilise la fonction suivante `charger_fichier(repertoire)`. Elle parcourt un repertoire donné, et initialise - pour chaque texte - un objet de type `Document`, pour lequel elle calcule les métriques de stylométrie, et qu'elle place dans un dictionnaire `textes`. Ce cera ce dictionnaire que l'on manipulera plus tard\n",
    "\n",
    "Comme on doit faire les précomputations et le calcul des métriques pour chaque texte, `charger_fichier()` est une fonction qui prend environ 20 minutes pour l'ensemble des textes utilisés. \n",
    "\n",
    "Attention à bien avoir comme repertoire courant le repertoire où se trouve le fichier `final.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hpa/CPES3/Analyse de Données/projet_2'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au cas où le repertoire courant n'est pas celui-là, utilisez `os.chdir()` avec les repertoires plus profonds ou avec `'..'` pour trouver le bon repertoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def charger_fichiers(repertoire):\n",
    "    # commencer timer\n",
    "    start = time.time()\n",
    "    \n",
    "    # Liste de fichiers dans repertoire, et changement de cwd\n",
    "    fichiers = sorted(os.listdir(repertoire))\n",
    "    os.chdir(repertoire)\n",
    "\n",
    "    textes = {}\n",
    "    for texte in fichiers: # Pour chaque fichier dans cwd, \n",
    "                           # creer un Document et realiser\n",
    "                           # les métriques\n",
    "        if texte.endswith('.txt'):\n",
    "            textes[texte] = Document(texte)\n",
    "            textes[texte]._stylographie()\n",
    "    \n",
    "    os.chdir('..')\n",
    "    \n",
    "    # terminer timer\n",
    "    end = time.time()\n",
    "    print(\"temps écoulé: \", end-start)\n",
    "    \n",
    "    return textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'exemple donné, utiliser le repertoire `'textes/'` qui contient les fichier .txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialisation de aristotle-on-263.txt\n",
      "texte aristotle-on-263.txt initialisé\n",
      "métriques de aristotle-on-263.txt calculées\n",
      "initialisation de aristotle-on-264.txt\n",
      "texte aristotle-on-264.txt initialisé\n",
      "métriques de aristotle-on-264.txt calculées\n",
      "initialisation de aristotle-on-265.txt\n",
      "texte aristotle-on-265.txt initialisé\n",
      "métriques de aristotle-on-265.txt calculées\n",
      "initialisation de aristotle-on-266.txt\n",
      "texte aristotle-on-266.txt initialisé\n",
      "métriques de aristotle-on-266.txt calculées\n",
      "initialisation de aristotle-on-267.txt\n",
      "texte aristotle-on-267.txt initialisé\n",
      "métriques de aristotle-on-267.txt calculées\n",
      "initialisation de aristotle-on-268.txt\n",
      "texte aristotle-on-268.txt initialisé\n",
      "métriques de aristotle-on-268.txt calculées\n",
      "initialisation de aristotle-on-269.txt\n",
      "texte aristotle-on-269.txt initialisé\n",
      "métriques de aristotle-on-269.txt calculées\n",
      "initialisation de aristotle-on-270.txt\n",
      "texte aristotle-on-270.txt initialisé\n",
      "métriques de aristotle-on-270.txt calculées\n",
      "initialisation de aristotle-on-271.txt\n",
      "texte aristotle-on-271.txt initialisé\n",
      "métriques de aristotle-on-271.txt calculées\n",
      "initialisation de aristotle-on-272.txt\n",
      "texte aristotle-on-272.txt initialisé\n",
      "métriques de aristotle-on-272.txt calculées\n",
      "initialisation de aristotle-on-273.txt\n",
      "texte aristotle-on-273.txt initialisé\n",
      "métriques de aristotle-on-273.txt calculées\n",
      "initialisation de aristotle-on-274.txt\n",
      "texte aristotle-on-274.txt initialisé\n",
      "métriques de aristotle-on-274.txt calculées\n",
      "initialisation de aristotle-on-82.txt\n",
      "texte aristotle-on-82.txt initialisé\n",
      "métriques de aristotle-on-82.txt calculées\n",
      "initialisation de aristotle-on-83.txt\n",
      "texte aristotle-on-83.txt initialisé\n",
      "métriques de aristotle-on-83.txt calculées\n",
      "initialisation de aristotle-on-84.txt\n",
      "texte aristotle-on-84.txt initialisé\n",
      "métriques de aristotle-on-84.txt calculées\n",
      "initialisation de aristotle-rhetoric-86.txt\n",
      "texte aristotle-rhetoric-86.txt initialisé\n",
      "métriques de aristotle-rhetoric-86.txt calculées\n",
      "initialisation de burroughs-at-316.txt\n",
      "texte burroughs-at-316.txt initialisé\n",
      "métriques de burroughs-at-316.txt calculées\n",
      "initialisation de burroughs-beasts-317.txt\n",
      "texte burroughs-beasts-317.txt initialisé\n",
      "métriques de burroughs-beasts-317.txt calculées\n",
      "initialisation de burroughs-ecore10.txt\n",
      "texte burroughs-ecore10.txt initialisé\n",
      "métriques de burroughs-ecore10.txt calculées\n",
      "initialisation de burroughs-gmars11.txt\n",
      "texte burroughs-gmars11.txt initialisé\n",
      "métriques de burroughs-gmars11.txt calculées\n",
      "initialisation de burroughs-gods-320.txt\n",
      "texte burroughs-gods-320.txt initialisé\n",
      "métriques de burroughs-gods-320.txt calculées\n",
      "initialisation de burroughs-jungle-321.txt\n",
      "texte burroughs-jungle-321.txt initialisé\n",
      "métriques de burroughs-jungle-321.txt calculées\n",
      "initialisation de burroughs-lcont10.txt\n",
      "texte burroughs-lcont10.txt initialisé\n",
      "métriques de burroughs-lcont10.txt calculées\n",
      "initialisation de burroughs-mmars10.txt\n",
      "texte burroughs-mmars10.txt initialisé\n",
      "métriques de burroughs-mmars10.txt calculées\n",
      "initialisation de burroughs-monster-323.txt\n",
      "texte burroughs-monster-323.txt initialisé\n",
      "métriques de burroughs-monster-323.txt calculées\n",
      "initialisation de burroughs-princess-324.txt\n",
      "texte burroughs-princess-324.txt initialisé\n",
      "métriques de burroughs-princess-324.txt calculées\n",
      "initialisation de burroughs-return-326.txt\n",
      "texte burroughs-return-326.txt initialisé\n",
      "métriques de burroughs-return-326.txt calculées\n",
      "initialisation de burroughs-son-333.txt\n",
      "texte burroughs-son-333.txt initialisé\n",
      "métriques de burroughs-son-333.txt calculées\n",
      "initialisation de burroughs-tarzan-334.txt\n",
      "texte burroughs-tarzan-334.txt initialisé\n",
      "métriques de burroughs-tarzan-334.txt calculées\n",
      "initialisation de burroughs-tarzan-335.txt\n",
      "texte burroughs-tarzan-335.txt initialisé\n",
      "métriques de burroughs-tarzan-335.txt calculées\n",
      "initialisation de burroughs-thuvia-336.txt\n",
      "texte burroughs-thuvia-336.txt initialisé\n",
      "métriques de burroughs-thuvia-336.txt calculées\n",
      "initialisation de burroughs-warlord-364.txt\n",
      "texte burroughs-warlord-364.txt initialisé\n",
      "métriques de burroughs-warlord-364.txt calculées\n",
      "initialisation de dickens-american-631.txt\n",
      "texte dickens-american-631.txt initialisé\n",
      "métriques de dickens-american-631.txt calculées\n",
      "initialisation de dickens-battle-630.txt\n",
      "texte dickens-battle-630.txt initialisé\n",
      "métriques de dickens-battle-630.txt calculées\n",
      "initialisation de dickens-chimes-379.txt\n",
      "texte dickens-chimes-379.txt initialisé\n",
      "métriques de dickens-chimes-379.txt calculées\n",
      "initialisation de dickens-christmas-125.txt\n",
      "texte dickens-christmas-125.txt initialisé\n",
      "métriques de dickens-christmas-125.txt calculées\n",
      "initialisation de dickens-cricket-127.txt\n",
      "texte dickens-cricket-127.txt initialisé\n",
      "métriques de dickens-cricket-127.txt calculées\n",
      "initialisation de dickens-david-626.txt\n",
      "texte dickens-david-626.txt initialisé\n",
      "métriques de dickens-david-626.txt calculées\n",
      "initialisation de dickens-dombey-622.txt\n",
      "texte dickens-dombey-622.txt initialisé\n",
      "métriques de dickens-dombey-622.txt calculées\n",
      "initialisation de dickens-hard-625.txt\n",
      "texte dickens-hard-625.txt initialisé\n",
      "métriques de dickens-hard-625.txt calculées\n",
      "initialisation de dickens-haunted-633.txt\n",
      "texte dickens-haunted-633.txt initialisé\n",
      "métriques de dickens-haunted-633.txt calculées\n",
      "initialisation de dickens-holiday-623.txt\n",
      "texte dickens-holiday-623.txt initialisé\n",
      "métriques de dickens-holiday-623.txt calculées\n",
      "initialisation de dickens-hunted-624.txt\n",
      "texte dickens-hunted-624.txt initialisé\n",
      "métriques de dickens-hunted-624.txt calculées\n",
      "initialisation de dickens-master-634.txt\n",
      "texte dickens-master-634.txt initialisé\n",
      "métriques de dickens-master-634.txt calculées\n",
      "initialisation de dickens-mystery-636.txt\n",
      "texte dickens-mystery-636.txt initialisé\n",
      "métriques de dickens-mystery-636.txt calculées\n",
      "initialisation de dickens-old-628.txt\n",
      "texte dickens-old-628.txt initialisé\n",
      "métriques de dickens-old-628.txt calculées\n",
      "initialisation de dickens-oliver-627.txt\n",
      "texte dickens-oliver-627.txt initialisé\n",
      "métriques de dickens-oliver-627.txt calculées\n",
      "initialisation de dickens-pickwick-635.txt\n",
      "texte dickens-pickwick-635.txt initialisé\n",
      "métriques de dickens-pickwick-635.txt calculées\n",
      "initialisation de dickens-pictures-632.txt\n",
      "texte dickens-pictures-632.txt initialisé\n",
      "métriques de dickens-pictures-632.txt calculées\n",
      "initialisation de dickens-speeches-621.txt\n",
      "texte dickens-speeches-621.txt initialisé\n",
      "métriques de dickens-speeches-621.txt calculées\n",
      "initialisation de dickens-tale-126.txt\n",
      "texte dickens-tale-126.txt initialisé\n",
      "métriques de dickens-tale-126.txt calculées\n",
      "initialisation de emerson-address-226.txt\n",
      "texte emerson-address-226.txt initialisé\n",
      "métriques de emerson-address-226.txt calculées\n",
      "initialisation de emerson-american-227.txt\n",
      "texte emerson-american-227.txt initialisé\n",
      "métriques de emerson-american-227.txt calculées\n",
      "initialisation de emerson-conduct-228.txt\n",
      "texte emerson-conduct-228.txt initialisé\n",
      "métriques de emerson-conduct-228.txt calculées\n",
      "initialisation de emerson-conservative-229.txt\n",
      "texte emerson-conservative-229.txt initialisé\n",
      "métriques de emerson-conservative-229.txt calculées\n",
      "initialisation de emerson-english-230.txt\n",
      "texte emerson-english-230.txt initialisé\n",
      "métriques de emerson-english-230.txt calculées\n",
      "initialisation de emerson-essays-231.txt\n",
      "texte emerson-essays-231.txt initialisé\n",
      "métriques de emerson-essays-231.txt calculées\n",
      "initialisation de emerson-essays-232.txt\n",
      "texte emerson-essays-232.txt initialisé\n",
      "métriques de emerson-essays-232.txt calculées\n",
      "initialisation de emerson-lecture-233.txt\n",
      "texte emerson-lecture-233.txt initialisé\n",
      "métriques de emerson-lecture-233.txt calculées\n",
      "initialisation de emerson-literary-234.txt\n",
      "texte emerson-literary-234.txt initialisé\n",
      "métriques de emerson-literary-234.txt calculées\n",
      "initialisation de emerson-man-235.txt\n",
      "texte emerson-man-235.txt initialisé\n",
      "métriques de emerson-man-235.txt calculées\n",
      "initialisation de emerson-method-236.txt\n",
      "texte emerson-method-236.txt initialisé\n",
      "métriques de emerson-method-236.txt calculées\n",
      "initialisation de emerson-nature-237.txt\n",
      "texte emerson-nature-237.txt initialisé\n",
      "métriques de emerson-nature-237.txt calculées\n",
      "initialisation de emerson-representative-238.txt\n",
      "texte emerson-representative-238.txt initialisé\n",
      "métriques de emerson-representative-238.txt calculées\n",
      "initialisation de emerson-transcendentalist-239.txt\n",
      "texte emerson-transcendentalist-239.txt initialisé\n",
      "métriques de emerson-transcendentalist-239.txt calculées\n",
      "initialisation de emerson-uncollected-240.txt\n",
      "texte emerson-uncollected-240.txt initialisé\n",
      "métriques de emerson-uncollected-240.txt calculées\n",
      "initialisation de emerson-young-241.txt\n",
      "texte emerson-young-241.txt initialisé\n",
      "métriques de emerson-young-241.txt calculées\n",
      "initialisation de hawthorne-alice-457.txt\n",
      "texte hawthorne-alice-457.txt initialisé\n",
      "métriques de hawthorne-alice-457.txt calculées\n",
      "initialisation de hawthorne-ambitious-467.txt\n",
      "texte hawthorne-ambitious-467.txt initialisé\n",
      "métriques de hawthorne-ambitious-467.txt calculées\n",
      "initialisation de hawthorne-artist-458.txt\n",
      "texte hawthorne-artist-458.txt initialisé\n",
      "métriques de hawthorne-artist-458.txt calculées\n",
      "initialisation de hawthorne-birthmark-459.txt\n",
      "texte hawthorne-birthmark-459.txt initialisé\n",
      "métriques de hawthorne-birthmark-459.txt calculées\n",
      "initialisation de hawthorne-celestial-477.txt\n",
      "texte hawthorne-celestial-477.txt initialisé\n",
      "métriques de hawthorne-celestial-477.txt calculées\n",
      "initialisation de hawthorne-dr-468.txt\n",
      "texte hawthorne-dr-468.txt initialisé\n",
      "métriques de hawthorne-dr-468.txt calculées\n",
      "initialisation de hawthorne-earths-471.txt\n",
      "texte hawthorne-earths-471.txt initialisé\n",
      "métriques de hawthorne-earths-471.txt calculées\n",
      "initialisation de hawthorne-egotism-463.txt\n",
      "texte hawthorne-egotism-463.txt initialisé\n",
      "métriques de hawthorne-egotism-463.txt calculées\n",
      "initialisation de hawthorne-ethan-461.txt\n",
      "texte hawthorne-ethan-461.txt initialisé\n",
      "métriques de hawthorne-ethan-461.txt calculées\n",
      "initialisation de hawthorne-feathertop-464.txt\n",
      "texte hawthorne-feathertop-464.txt initialisé\n",
      "métriques de hawthorne-feathertop-464.txt calculées\n",
      "initialisation de hawthorne-great-466.txt\n",
      "texte hawthorne-great-466.txt initialisé\n",
      "métriques de hawthorne-great-466.txt calculées\n",
      "initialisation de hawthorne-hollow-470.txt\n",
      "texte hawthorne-hollow-470.txt initialisé\n",
      "métriques de hawthorne-hollow-470.txt calculées\n",
      "initialisation de hawthorne-house-64.txt\n",
      "texte hawthorne-house-64.txt initialisé\n",
      "métriques de hawthorne-house-64.txt calculées\n",
      "initialisation de hawthorne-lady-472.txt\n",
      "texte hawthorne-lady-472.txt initialisé\n",
      "métriques de hawthorne-lady-472.txt calculées\n",
      "initialisation de hawthorne-maypole-474.txt\n",
      "texte hawthorne-maypole-474.txt initialisé\n",
      "métriques de hawthorne-maypole-474.txt calculées\n",
      "initialisation de hawthorne-ministers-473.txt\n",
      "texte hawthorne-ministers-473.txt initialisé\n",
      "métriques de hawthorne-ministers-473.txt calculées\n",
      "initialisation de hawthorne-mr-469.txt\n",
      "texte hawthorne-mr-469.txt initialisé\n",
      "métriques de hawthorne-mr-469.txt calculées\n",
      "initialisation de hawthorne-my-475.txt\n",
      "texte hawthorne-my-475.txt initialisé\n",
      "métriques de hawthorne-my-475.txt calculées\n",
      "initialisation de hawthorne-old-462.txt\n",
      "texte hawthorne-old-462.txt initialisé\n",
      "métriques de hawthorne-old-462.txt calculées\n",
      "initialisation de hawthorne-peter-479.txt\n",
      "texte hawthorne-peter-479.txt initialisé\n",
      "métriques de hawthorne-peter-479.txt calculées\n",
      "initialisation de hawthorne-prophetic-476.txt\n",
      "texte hawthorne-prophetic-476.txt initialisé\n",
      "métriques de hawthorne-prophetic-476.txt calculées\n",
      "initialisation de hawthorne-rappaccinis-460.txt\n",
      "texte hawthorne-rappaccinis-460.txt initialisé\n",
      "métriques de hawthorne-rappaccinis-460.txt calculées\n",
      "initialisation de hawthorne-scarlet-63.txt\n",
      "texte hawthorne-scarlet-63.txt initialisé\n",
      "métriques de hawthorne-scarlet-63.txt calculées\n",
      "temps écoulé:  890.7362082004547\n"
     ]
    }
   ],
   "source": [
    "textes = charger_fichiers('textes/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le temps écoulé est de 890 secondes, soit plus ou moins 15 minutes. \n",
    "\n",
    "Si vous n'avez pas le temps pour laisser courrir le programme sur les données entières, je laisse aussi un dossier `textes_small/` avec 3 auteurs et 6 textes par auteur. Comme j'utilise beaucoup de métriques, avec peu de données les modèles ne s'entrainent pas bien donc la performance finale peut ne pas être très bonne. Mais toutes les fonctions sont indépendantes du nombre d'auteurs et de textes, donc pas de problème pour tester le programme. \n",
    "\n",
    " - Attention: si vous utilisez `textes_small/`, oubliez pas de changer le nombre de données utilisées pour l'entrainement lorsque vous définissez le modèle. \n",
    "\n",
    "Ici je ne peux pas non plus juste sauvegarder le dictionnaire `textes` dans un fichier, vu qu'il est difficile de sérialiser étant donné que c'est un dictionnaire composé d'objets, qui eux mêmes sont composés de listes, de dictionnaires de listes, entre autres. Le temps qu'il faudrait pour désérialiser et mettre en mémoire est le même que le calculer soi même"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatation des données, séparation train/test, et métriques supplémentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut maintenant transformer les données dans un format utilisable par un algorithme de classification. Il faut donc les tranformer dans une array de caractéristiques, de features, et dans une array de labels.\n",
    "\n",
    "Pour ça, je crée une classe que j'appelle `modele`, et qui contient toutes les méthodes nécessaires pour faire cette formatation\n",
    "\n",
    "La classe Modele est initialisée par un corpus de textes (obtenu dans la partie précédante avec `charger_fichiers`) et une liste d'auteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour faire une séparation entre un ensemble de textes dédiés à l'entrainement, et un ensemble de textes dédié aux tests, je crée une méthode de classe `_separation_train_test(nb_train)`, qui prend en paramètre le nombre de textes dédiés à l'entrainement, par auteur. C'est important que le nombre de textes d'entrainement soit le même pour chaque auteur, pour qu'il n'y ais pas de biais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrique supplémentaire: mots les plus fréquents pour chaque auteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je veux aussi implémenter une métrique supplémentaire, qui est démontrée très efficace: c'est la Delta Measure de John Burrow. Elle calcule la distance entre le vocabulaire d'un texte et le vocabulaire du corpus entier de l'auteur.\n",
    "\n",
    "J'ai implémenter une version simplifiée: pour chaque auteur, je calcule les 30 mots les plus utilisés. Ensuite, pour chaque texte, je calcule la proportion que représentent les 30 mots les plus utilisés par chaque auteur dans ce texte. Je calcule, pour chaque texte, cette proportion pour chaque auteur.\n",
    "\n",
    "L'idée est que la proportion du vocabulaire le plus utilisé par un auteur dans un texte sera plus haute si ce texte provient de cet auteur.\n",
    "\n",
    "Attention, pour calculer les 30 mots les plus utilisés par chaque auteur dans leurs corpus, je ne dois prendre en compte que les données d'entrainement.\n",
    "\n",
    "J'implémente cette mesure dans une méthode de classe `_frequence_mots_auteurs()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatation des données pour l'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dit précédemment, je dois maintenant assembler les données dans un format utilisable par des algorithmes de classification: je dois donc séparer les features des labels, et additionner la métrique donnant la proportion de vocabulaire le plus utilisé par chaque auteur pour chaque texte.\n",
    "\n",
    "Les métriques composées, soit la ponctuation, doivent être décomposées en valeurs unitaires: je le fait dans la méthode `_matrice_carractéristiques()`\n",
    "\n",
    "Cette méthode donne 4 matrices: les features et labels pour l'entrainement, et celles pour les tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe Modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je place les méthodes décrites précédament dans la classe suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modele(object):\n",
    "    def __init__(self, textes):\n",
    "        self.textes  = textes\n",
    "        self.auteurs = list(set([self.textes[texte].auteur for texte in self.textes]))\n",
    "        \n",
    "        \n",
    "    # Méthode séparant les textes dans deux groupes, pour entrainer et tester en\n",
    "    # gardant le meme nombre de textes par autheur dans l'entrainement\n",
    "    def _separation_train_test(self, nb_train):\n",
    "        train = {}\n",
    "        test = {}\n",
    "\n",
    "        for auteur in self.auteurs: # Pour chaque auteur, il faut nb_train\n",
    "                                    # textes pour l'entrainement, et le reste\n",
    "                                    # pour le test\n",
    "            ct_auteur = 0\n",
    "\n",
    "            for texte in self.textes:\n",
    "                # si nb_textes_auteur < nb_train: auteur -> train\n",
    "                if self.textes[texte].auteur == auteur and ct_auteur < nb_train:\n",
    "                    train[self.textes[texte].fichier] = self.textes[texte]\n",
    "                    ct_auteur += 1\n",
    "                # sinon: auteur -> test\n",
    "                elif self.textes[texte].auteur == auteur:\n",
    "                    test[self.textes[texte].fichier] = self.textes[texte]\n",
    "        \n",
    "        self.train = train\n",
    "        self.test  = test\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Méthode calculant les mots les plus fréquents d'un corpus de textes\n",
    "    # pour un auteur donné. Ne prend que en compte les auteurs dans train\n",
    "    def _frequence_mots_auteurs(self):\n",
    "        frequence_mots_auteurs = {}\n",
    "\n",
    "        for auteur in self.auteurs:\n",
    "            freq_auteur = nltk.FreqDist()\n",
    "\n",
    "            for texte in self.train:\n",
    "                if textes[texte].auteur == auteur:\n",
    "                    freq_auteur += self.train[texte].freq_occurences\n",
    "\n",
    "            frequence_mots_auteurs[auteur] = freq_auteur.most_common(30)\n",
    "\n",
    "        self.frequence_mots_auteurs = frequence_mots_auteurs\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Méthode transformant les données dans un format utilisable par les classificateurs,\n",
    "    # soit une matrice de caractéristiques. Pour train et test.\n",
    "    def _matrice_caracteristiques(self):\n",
    "        for donnees in [self.train, self.test]:\n",
    "            features = []\n",
    "            labels   = []\n",
    "\n",
    "            for texte in donnees:\n",
    "                features_texte = []\n",
    "\n",
    "                len_texte = len(donnees[texte].mots_sans_punct_chif_stop)\n",
    "\n",
    "                # Caractéristiques directement récupérables dans les attributs du texte\n",
    "                features_texte.append(donnees[texte].len_moy_mots[0])\n",
    "                features_texte.append(donnees[texte].len_moy_mots[1])\n",
    "                features_texte.append(donnees[texte].len_moy_phrase_caracteres)\n",
    "                features_texte.append(donnees[texte].len_moy_phrase_mots)\n",
    "                features_texte.append(donnees[texte].nb_moy_syllabes_mots)\n",
    "                features_texte.append(donnees[texte].hapax_legomenon / len_texte)\n",
    "                features_texte.append(donnees[texte].proportion_stop)\n",
    "\n",
    "                # Proportion ponctuation\n",
    "                for ponct in string.punctuation:\n",
    "                    features_texte.append(donnees[texte].ponctuation[ponct] / len_texte)\n",
    "\n",
    "                # Proportion des mots les plus utilises par chaque auteur dans le texte courant\n",
    "                for auteur in self.auteurs:\n",
    "                    ct_mots_freq_auteur = 0\n",
    "                    for mot in self.frequence_mots_auteurs[auteur]:\n",
    "                        ct_mots_freq_auteur += donnees[texte].mots_sans_punct_chif_stop.count(mot)\n",
    "                    freq = ct_mots_freq_auteur / len_texte\n",
    "\n",
    "                    features_texte.append(freq)\n",
    "\n",
    "                # Donnée courante\n",
    "                features.append(features_texte)\n",
    "                labels.append(donnees[texte].auteur)\n",
    "                \n",
    "            if donnees == self.train:\n",
    "                self.matrice_features_train = np.array(features)\n",
    "                self.matrice_labels_train   = np.array(labels)\n",
    "            elif donnees == self.test:\n",
    "                self.matrice_features_test  = np.array(features)\n",
    "                self.matrice_labels_test    = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du Modele\n",
    "\n",
    "On va maintenant créer un modèle avec les données obtenues dans la première partie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele1 = modele(textes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit ensuite faire la séparation entre données d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele1._separation_train_test(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule les mots les plus utiliséss par chaque auteur dans leur corpus (à partir des données d'entrainement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele1._frequence_mots_auteurs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit ensuite la matrice des caractéristiques, qui comporte les données dans le bon format et avec la métrique supplémentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele1._matrice_caracteristiques()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: il n'est pas nécessaire de normaliser la matrice vu que toutes les données sont déjà des proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant tester deux algorithmes de classification: K-Nearest-Neighbours et Random Forrest Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée également une fonction qui nous permettra de visualiser des matrices de confusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_de_confusion(y,y_pred,auteurs):\n",
    "    cm = confusion_matrix(y,y_pred,labels = list(set(y)))\n",
    "    \n",
    "    df_cm = pd.DataFrame(cm, \n",
    "                         index = [i for i in auteurs],\n",
    "                         columns = [i for i in auteurs])\n",
    "    \n",
    "    plt.figure(figsize = (10,7))\n",
    "    \n",
    "    return sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest-Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir tester plusieurs valeurs de K, 3 semble obtenir le meilleur résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(modele1.matrice_features_train,modele1.matrice_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn.predict(modele1.matrice_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff42fa10b10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGfCAYAAACNytIiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZgcdbn3//dnJpMEJGwGJAuQABHZRIQgKHKBeABlU0HQR46AeIIim5wDHjzIqr/zgDwgiCJBlqBHJKKQsAnKDrIk7JCwBiQTckC2bCQhmbl/f1QNtJPJdE3S1TXV/Xnlqmtq7zs1Nd13f7dSRGBmZmZWlJaiAzAzM7Pm5mTEzMzMCuVkxMzMzArlZMTMzMwK5WTEzMzMCuVkxMzMzArlZMTMzMz6RFKrpEcl3dDDtkGSrpb0gqQHJY2qdj4nI2ZmZtZXxwLTl7PtcODtiNgEOA84q9rJnIyYmZlZZpJGAnsBv17OLvsBE9L5a4DdJKm3cw6oXXg9+9aoAzzEq5Xela/eX3QIZjXxwLpjiw6hKWzXfl2vH761tuSNGTX7rB24zsZHAOMqVo2PiPEVyz8DTgSGLOcUI4CZABGxVNIc4MPAG8t7zdyTETMzMyuPNPEY39M2SXsDr0fEw5J2Wc4pekrEek2WnIyYmZmVXWdHvV7pM8C+kr4IDAZWl/TbiDi4Yp92YH2gXdIAYA3grd5O6jYjZmZmlklEnBQRIyNiFPA14PZuiQjAZOCQdP6AdB+XjJiZmTW06Cz05SWdAUyNiMnApcBvJL1AUiLytWrHOxkxMzMru876JyMRcSdwZzp/SsX6RcBX+3IuV9OYmZlZoVwyYmZmVnJRcDXNynIyYmZmVnYFVNPUkqtpzMzMrFAuGTEzMys7V9OYmZlZoeo36FkuXE1jZmZmhXLJiJmZWdm5msbMzMwK5d40ZmZmZivOJSNmZmYl50HPzMzMrFiupjEzMzNbcS4ZMTMzKztX05iZmVmhPOiZmZmZ2YpzyYiZmVnZuZrGzMzMCuXeNGZmZmYrziUjZmZmZedqGjMzMyuUq2nMzMzMVpxLRszMzEouotzjjDgZMTMzK7uStxlxNY2ZmZkVyiUjZmZmZVfyBqxORszMzMqu5NU0TkbMzMzKzg/KaxyHnX0kP5t6KWfccm7RoTQsX+P62GP3XXj6qbt5Ztq9nHjC94oOpyH5GuevbdhQPjrxTLa44+dscdsFrHv43kWHZDlxMlLhvmvu4NxDflx0GA3N1zh/LS0tXHD+T9h7n4PZautdOeigL7HZZmOKDquh+BrXSUcH7WdcztO7Hs30fU9k3UO+wOAxI4uOqn+KztpNBXAyUuG5h6azYM78osNoaL7G+dt+7Da8+OLLvPTSKyxZsoSJEyex7z57FB1WQ/E1ro8lr7/Nu0/NAKBzwSIWPt/OwPU+XHBU/VRnZ+2mAjgZMWsww0esx8z2V99fbp81m+HD1yswosbja1x/A0euy6pbbsT8R58rOhTLQaYGrJI+CpwAbFh5TER8bjn7jwPGAXx67W3YdMhGKx+pmWUiaZl1EVFAJI3L17i+WlYdzMbjf8DM0y6lc/7CosPpn5qkN80fgF8BlwBVm+xGxHhgPMC3Rh3gv1CzOprVPpv1Rw5/f3nkiGHMnv1agRE1Hl/j+tGAVjYe/wPeuvYu3rn5gaLD6b9KPs5I1mqapRFxUUQ8FBEPd025RmZmK2TK1MfYZJPRjBq1Pm1tbRx44H5cf8OtRYfVUHyN62fDc45i0QvtvHbJ5KJDsRxlLRm5XtKRwLXA4q6VEfFWLlEV5IgLjmPTHbZgtbWGcM79FzPpvKu5Z+LtRYfVUHyN89fR0cGxx53MTTf+jtaWFq6YcDXTprmevZZ8jetjtbGbMfSAXXl3+stsfst5AMw667fMud3fhZdR8pIRZannlPRSD6sjIqo2BnE1jTWCK1+9v+gQzGrigXXHFh1CU9iu/bplGxblaOHdV9Tss3aVnQ+ta+yQsWQkIkbnHYiZmZk1p6y9adqA7wI7p6vuBC6OiCU5xWVmZmZZlbyaJmsD1ouAbYFfptO26TozMzMrWp1GYJU0WNJDkh6X9LSk03vY51BJ/5D0WDp9u1r4WRuwjo2IrSuWb5f0eMZjzczMrDEsBj4XEfPTWpN7Jd0cEd37XV8dEUdlPWnWZKRD0sYR8SKApI3IMN6ImZmZ1UGdqmki6fXS9UyPtnRa6cazWZORE4A7JM0ARDIS62Er++JmZmZWAzUcgbVyFPXU+HQw067trcDDwCbALyLiwR5Os7+knYHngO9HxMzeXjNrb5rbJI0BNiVJRp6JiMVVDjMzM7OSqRxFfTnbO4BPSFoTuFbSlhHxVMUu1wNXRcRiSd8BJgA9Pj6mS6YGrJK+CgyMiCeAfYCrJH0yy7FmZmaWswKe2hsR75D0rt2z2/o3KwosLiHp9NKrrL1pfhQR8yTtBOxBkuW4N42ZmVl/UL/eNOukJSJIWgX4PPBMt32GVSzuC0yvFn7WZKSrsepewEURMQkYmPFYMzMzawzDSNqQPgFMAf4SETdIOkPSvuk+x6Tdfh8HjgEOrXbSrA1YZ0m6mCQDOkvSILInMmZmZpan+vWmeQLYpof1p1TMnwSc1JfzZk1GDiSpEzonIt5Ji2BO6MsLmZmZWU5KPgJr1WREUgvwUERs2bUuImYDs/MMzMzMzJpD1WQkIjrTYV83iIhX6hGUmZmZ9UENxxkpQtZqmmHA05IeAhZ0rYyIfZd/iJmZmdVFo1fTpJZ5EI6ZmZlZLWQdgfUuSRsCYyLir5JWBVrzDc3MzMwyaYZqGkn/RjJO/drAxsAI4FfAbvmFZmZmZpmUvJom61gh3wM+A8wFiIjngXXzCsrMzMyaR9Y2I4sj4j1JAEgaQA0eGWxmZmY10AzVNMBdkn4IrCLpX4AjSZ7KZ2ZmZkVrkmqa/wT+ATwJHAHcBJycV1BmZmbWPLL2pukkeQzwJfmGY2ZmZn3WDCUjkvaW9KiktyTNlTRP0ty8gzMzM7MMImo3FSBrm5GfAV8BnowoKFIzMzNrSFmTkZnAU05EzMzM+qGSV9NkTUZOBG6SdBewuGtlRJybS1RmZmaWXZMkIz8B5gODgYH5hWNmZmbNJmsysnZE7J5rJGZmZrZiSj7oWdZxRv4qycmImZlZf9TZWbupAH15Ns3Nkha6a6+ZmZnVUtZqmjWAbwCjI+IMSRsAw/ILy8zMzDIreWfXrCUjvwB2AL6eLs8DLswlIjMzM+ubklfTZC0Z+VREfFLSowAR8bakTL1qLp569goHZ9ksufTMokNoeFf+qOgImsPcM900LW9HXTSv6BCawmVFB1AyWZORJZJagQCQtA5Q7qa7ZmZmjaJJxhm5ALgWWFfST4AD8FN7zczM+oeSd+3N+tTe/5H0MLAbIOBLETE918jMzMysKWQtGSEingGeyTEWMzMzWwHRWe7eNJmTETMzM+unSt5mJGvXXjMzM7NcuGTEzMys7JqhAauZmZn1YyVvM+JqGjMzMyuUS0bMzMzKruQNWJ2MmJmZlZ2TETMzMytUkzy118zMzCwXLhkxMzMrO1fTmJmZWaHctdfMzMyagaTBkh6S9LikpyWd3sM+gyRdLekFSQ9KGlXtvE5GzMzMyi46azf1bjHwuYjYGvgEsKekHbrtczjwdkRsApwHnFXtpE5GzMzMyq4zajf1IhLz08W2dOp+0H7AhHT+GmA3SertvE5GzMzM7H2SxkmaWjGN67a9VdJjwOvAXyLiwW6nGAHMBIiIpcAc4MO9vaYbsJqZmZVc1LA3TUSMB8b3sr0D+ISkNYFrJW0ZEU9V7NJTKUivRS4uGTEzMyu7OlXTVIqId4A7gT27bWoH1geQNABYA3irt3M5GTEzM7NMJK2TloggaRXg88Az3XabDBySzh8A3B7R+xCxrqYxMzMru+q9YGplGDBBUitJgcbEiLhB0hnA1IiYDFwK/EbSCyQlIl+rdlInI2ZmZmVXp0HPIuIJYJse1p9SMb8I+GpfzutqGjMzMyuUS0bMzMzKzs+mMTMzs0L52TRmZmZmK84lI2ZmZmVXv940uXAyYmZmVnaupjEzMzNbcS4ZMTMzK7laPpumCE5GzMzMyq7k1TRORrrp6OjgoMOPYd11hvLLn55edDiNp3UAg/7PSWjAAGhppePZqSy597qio2o4e+y+C+eeewatLS1cdvlVnP3TXxQdUmPxfVwXh519JFt/blvmvjmHU/Y4vuhwLEdORrr57R8msdGoDZi/4N2iQ2lMHUtZ/PuzYcliaGll0DdOomXGE3S+OqPoyBpGS0sLF5z/E/b84tdpb5/NA/ffxPU33Mr06c8XHVrj8H1cF/ddcwe3TbiZb597dNGh9H8lLxlxA9YK//v6P7j7bw+x/z57FB1KY1uyOPnZ0opaBkC5/4b6ne3HbsOLL77MSy+9wpIlS5g4cRL7+p6uPd/HuXvuoeksmDO/6DDKITprNxXAJSMVzjr/Yo4/8nAWvLuw6FAam8TgQ05Da63L0kdup3O2v03W0vAR6zGz/dX3l9tnzWb7scs818pWlu9js5rJVDIi6aOSbpP0VLr8cUkn97L/OElTJU399ZVX1SrWXN1534OsvdaabPGxMUWH0vgiWHTFqSz85fG0DBuNho4oOqKGImmZdRH+2l5zvo+tP+mM2k0FyFoycglwAnAxJI8QlvQ74Mc97RwR44HxAEvemFGKd8FHn5jGnfc+wD33T2Hxe0tYsOBdfnD62Zx16olFh9a4Fi+kY+aztG60FUvfmFV0NA1jVvts1h85/P3lkSOGMXv2awVG1OB8H1s/EE3SZmTViHio27qltQ6mSN//7mHcdt1vufWPE/jp6f/J9ttu7UQkD6sMgUGrJPMD2mjdcHM635xdbEwNZsrUx9hkk9GMGrU+bW1tHHjgflx/w61Fh9VYfB+b1VTWkpE3JG1M2kRL0gGA//Ksz7TaGgza69ugFpBY+swUOl98vOiwGkpHRwfHHncyN934O1pbWrhiwtVMm/Zc0WE1FN/H9XHEBcex6Q5bsNpaQzjn/ouZdN7V3DPx9qLD6p9KXjKiLHXJkjYiqXb5NPA28BJwcES8XO3YslTTlNmSS88sOoSGt/qPXLJQD3PP3L3oEBreURfNKzqEpnDZy9cs23grR/OO+mLNPmuHXHhTXWOHjCUjETED+LykDwEtEeG72czMzGoiUzIiaRCwPzAKGNDVWj8izsgtMjMzM8um5NU0WduMTALmAA8Di/MLx8zMzPqsSZKRkRGxZ66RmJmZWVPKmoz8TdJWEfFkrtGYmZlZn5V9YMOsychOwKGSXiKpphEQEfHx3CIzMzOzbJqkmuYLuUZhZmZmTatqMiKpBbgxIrasQzxmZmbWV41eMhIRnZIel7RBRLxSj6DMzMwsu7I/myZrNc0w4GlJDwELulZGxL65RGVmZmZNI2sycnquUZiZmdmKa4aSkYi4S9JHgLHpqoci4vX8wjIzM7PMOosOYOW0ZNlJ0oHAQ8BXgQOBB9Mn95qZmZmtlKzVNP8FjO0qDZG0DvBX4Jq8AjMzM7NsmqUBa0u3apk3yViqYmZmZjlrkmTkz5JuAa5Klw8CbsonJDMzM2smWRuwniBpf+AzJEPBj4+Ia3ONzMzMzLIpeQPWrCUjRMQfgT/mGIuZmZmtgLK3Gcnam+Yrkp6XNEfSXEnzJM3NOzgzMzNrfFlLRs4G9omI6XkGY2ZmZiugSappXnMiYmZm1j+VvZqm12RE0lfS2amSrgauAxZ3bY+IP+UYm5mZmfUjktYHrgTWIymPGR8R53fbZxdgEvBSuupPEXFGb+etVjKyT8X8u8DuFcsBOBkxMzMrWv2qaZYC/x4Rj0gaAjws6S8RMa3bfvdExN5ZT9prMhIRhwFI+kxE3Fe5TdJnsr6ImZmZ5SfqlIxExGxgdjo/T9J0YATQPRnpk6yjqP484zozMzOrt87aTZLGSZpaMY3r6SUljQK2AR7sYfOOkh6XdLOkLaqFX63NyI7Ap4F1JB1fsWl1oLXayc3MzKxcImI8ML63fSStRjL22HER0X2oj0eADSNivqQvkrQ3HdPb+aqVjAwEViNJWoZUTHMBP7XXzMysH4jO2k3VSGojSUT+p6eOLBExNyLmp/M3AW2ShvZ2zmptRu4C7pL024h4sXqIZmZmVnd1ajMiScClwPSIOHc5+6xHMiRISNqepODjzd7Om3WckcsljQCmAHeTtJJ9MnP0ZmZm1gg+A/wr8KSkx9J1PwQ2AIiIX5HUnHxX0lJgIfC1iOh1IJSsD8rbWdJAYCywC3CjpNUiYu0V+Z+YmZlZ7dSxN829JA/M7W2fC4EL+3LeTMmIpJ2Az6bTmsANwD19eSEzMzPLR72Skbxkraa5C5gK/DdwU0S8l19IZmZm1kyyJiMfJqkn2hk4RlIncH9E/Ci3yMzMzCyTpigZiYh3JM0A1gdGkow90pbl2CO2O3HFo7NMrnz1/qJDaHhzz9y9+k620o66aF7RITS8I5cuLToEy0P02oyj38vaZuRF4FngXuBXwGGuqjEzM7NayFpNMyai7IVAZmZmjansn9BZk5GBkg4HtgAGd62MiG/lEpWZmZllFp3lrqbJ+qC83wDrAXuQ9KwZCbhy18zMzFZa1mRkk7TnzIKImADsBWyVX1hmZmaWVT2fTZOHrNU0S9Kf70jaEvhfYFQuEZmZmVmfRDP0pgHGS1oLOBmYTPIkX48xYmZmZistazLyG2B/ktKQCem6j+QRkJmZmfVNs/SmmQTMAR4GFucXjpmZmfVV2XvTZE1GRkbEnrlGYmZmZk0pa2+av0ly7xkzM7N+KKJ2UxF6LRmR9CQQ6X6Hpc+nWQwIiIj4eP4hmpmZWW8avZpm77pEYWZmZk2r12QkIv5er0DMzMxsxTR6yYiZmZn1c0W19aiVrA1YzczMzHLhkhEzM7OSczWNmZmZFarsz6ZxNY2ZmZkVyiUjZmZmJdcsz6YxMzOzfqrT1TRmZmZmK84lI2ZmZiVX9gasTkbMzMxKruxde11NY2ZmZoVyyYiZmVnJlX04eCcjZmZmJedqGjMzM7OV4JIRMzOzkiv7OCNORszMzEqu7F17XU1jZmZmhXLJiJmZWcm5N42ZmZkVym1GGshhZx/J1p/blrlvzuGUPY4vOpyGtcfuu3DuuWfQ2tLCZZdfxdk//UXRITWW1gEM+j8noQEDoKWVjmensuTe64qOquH4/SJ/bcOGMvr8Y2lbZ03oDP7xu1t5/dIbig7LcuA2IxXuu+YOzj3kx0WH0dBaWlq44PyfsPc+B7PV1rty0EFfYrPNxhQdVmPpWMri35/NostPZdHlp9Iyektahm9UdFQNx+8XddDRQfsZl/P0rkczfd8TWfeQLzB4zMiio+qXIlSzqTeS1pd0h6Tpkp6WdGwP+0jSBZJekPSEpE9Wi9/JSIXnHprOgjnziw6joW0/dhtefPFlXnrpFZYsWcLEiZPYd589ig6r8SxZnPxsaUUtA6Dk9cn9kd8v8rfk9bd596kZAHQuWMTC59sZuN6HC46qf4qo3VTFUuDfI2IzYAfge5I277bPF4Ax6TQOuKjaSV1NY3U1fMR6zGx/9f3l9lmz2X7sNgVG1KAkBh9yGlprXZY+cjuds2cUHZHZShk4cl1W3XIj5j/6XNGhNLWImA3MTufnSZoOjACmVey2H3BlRATwgKQ1JQ1Lj+1RppIRSV+VNCSdP1nSn7IUu5h1Jy1bBBhlbwbeH0Ww6IpTWfjL42kZNhoNHVF0RGYrrGXVwWw8/gfMPO1SOucvLDqcfqkzVLMpK0mjgG2AB7ttGgHMrFhuT9ctV9Zqmh+lGdBOwB7ABHopdpE0TtJUSVOfnedvZPaBWe2zWX/k8PeXR44YxuzZrxUYUYNbvJCOmc/SutFWRUditkI0oJWNx/+At669i3dufqDocPqtWrYZqfwMT6dx3V9P0mrAH4HjImJu9809hdhb/FmTkY70517ARRExCRi4vJ0jYnxEbBcR2206xA3n7ANTpj7GJpuMZtSo9Wlra+PAA/fj+htuLTqsxrLKEBi0SjI/oI3WDTen883llo6a9WsbnnMUi15o57VLJhcdStOo/AxPp/GV2yW1kSQi/xMRf+rhFO3A+hXLI4FXe9jvfVnbjMySdDHweeAsSYNowMavR1xwHJvusAWrrTWEc+6/mEnnXc09E28vOqyG0tHRwbHHncxNN/6O1pYWrphwNdOmuQ64lrTaGgza69ugFpBY+swUOl98vOiwGo7fL/K32tjNGHrArrw7/WU2v+U8AGad9Vvm3P5wwZH1P/UaZ0RJXfulwPSIOHc5u00GjpL0e+BTwJze2osAKEt9vaRVgT2BJyPieUnDgK0ioupX2m+NOsANAnJ25av3Fx1Cw5t75u5Fh9AUjrpoXtEhNLwjly4tOoSmsF37dXUdheyB4V+p2WftDq/+abmxp8017gGeBDrT1T8ENgCIiF+lCcuFJHnDu8BhETG1t9fMVDISEe9KmgR8RNIG6epnshxrZmZm+apXyUhE3EvPbUIq9wnge305b6ZkRNLRwKnAa3yQCQXw8b68mJmZmVl3WduMHAtsGhFv5hmMmZmZ9V21kVP7u6zJyExgTp6BmJmZ2YrprL5Lv5Y1GZkB3CnpRmBx18peWtKamZmZZZI1GXklnQbSy/giZmZmVn/Re5vSfi9rb5rTASR9KCIW5BuSmZmZ9UVnyQfRyPpsmh0lTQOmp8tbS/plrpGZmZlZU8g6iurPSJ5J8yZARDwO7JxXUGZmZpZdJ6rZVISsbUaIiJndnrjasbx9zczMrH6aos0IMFPSp4GQNBA4hrTKxszMzGxlZE1GvgOcD4wgeRrfrfRxqFczMzPLR7OMM9IZEd+oXCFpNGkbEjMzMytO2atpsjZgvV7S6l0LkjYDrs8nJDMzM2smWZOR/48kIVlN0rbANcDB+YVlZmZmWXXWcCpC1kHPbpTURtJWZAjwpYh4PtfIzMzMLJOGbjMi6edA5bhuq5M8p+ZoSUTEMXkGZ2ZmZo2vWsnI1G7LD+cViJmZma2Ysjdg7TUZiYgJkDyTBlgUER3pciswKP/wzMzMrJrOcucimRuw3gasUrG8CvDX2odjZmZmzSbrOCODI2J+10JEzJe0ak4xmZmZWR8U9UyZWslaMrJA0ie7FtLuvQvzCcnMzMz6Imo4FSFrychxwB8kvZouDwMOyickMzMzayZZxxmZIuljwKaAgGciYkmukZmZmVkmjT7OyOci4nZJX+m2aUw6zsifcozNzMzMMuhUuduMVCsZ2Rm4HdiHf65KUrrsZMTMzMxWSrVkZJ6k44GnSJKPrtSrqDYuZmZm1k3ZP5SrJSOrpT83BcYCk0gSkn2Au3OMy8zMzDJq6DYjEXE6gKRbgU9GxLx0+TTgD7lHZ2ZmZg0va9feDYD3KpbfA0bVPBozMzPrs7IPB581GfkN8JCka0mqpr4MTMgtKjMzM8us7COwZh1n5CeSbgY+m646LCIezS8sMzMzaxZZS0aIiEeAR3KMxczMzFZAo/emWWlXvnp/3i/R9L45fMeiQ2h4R100r+gQmsKRS5cWHULD2+H1KUWH0BTqfSeXvc1I1gflmZmZmeUi95IRMzMzy1dDjzNiZmZm/V/Z24y4msbMzMwK5ZIRMzOzkit7A1YnI2ZmZiVX9jYjrqYxMzOzzCRdJul1SU8tZ/sukuZIeiydTql2TpeMmJmZlVydS0auAC4Eruxln3siYu+sJ3QyYmZmVnJRxzYjEXG3pFG1PKeraczMzOx9ksZJmloxjVuB0+wo6XFJN0vaotrOLhkxMzMruVpW00TEeGD8SpziEWDDiJgv6YvAdcCY3g5wyYiZmVnJddZwWlkRMTci5qfzNwFtkob2doyTETMzM6sZSetJUjq/PUmu8WZvx7iaxszMrOTqORy8pKuAXYChktqBU4E2gIj4FXAA8F1JS4GFwNciotcQnYyYmZmVXD1HYI2Ir1fZfiFJ19/MXE1jZmZmhXLJiJmZWcmVfTh4JyNmZmYlV/ZkxNU0ZmZmViiXjJiZmZVcPXvT5MHJiJmZWcnVszdNHpyMmJmZlZzbjJiZmZmtBJeMmJmZlZzbjJiZmVmhOkuejriaxszMzArlkhEzM7OSK3sDVicjZmZmJVfuShpX05iZmVnBXDJiZmZWcq6mMTMzs0KVfQRWV9OYmZlZoVwyYmZmVnJlH2fEyYiZmVnJlTsVcTXNP9lj9114+qm7eWbavZx4wveKDqchHXb2kfxs6qWcccu5RYfSsHyN89c2bCgfnXgmW9zxc7a47QLWPXzvokNqSH5Pbh5ORlItLS1ccP5P2Hufg9lq61056KAvsdlmY4oOq+Hcd80dnHvIj4sOo6H5GtdBRwftZ1zO07sezfR9T2TdQ77A4DEji46qofg9uW86azgVwclIavux2/Diiy/z0kuvsGTJEiZOnMS+++xRdFgN57mHprNgzvyiw2hovsb5W/L627z71AwAOhcsYuHz7Qxc78MFR9VY/J7cN51EzaYiZEpGJH1V0pB0/mRJf5L0yXxDq6/hI9ZjZvur7y+3z5rN8OHrFRiRmZXBwJHrsuqWGzH/0eeKDqWh+D25uWQtGflRRMyTtBOwBzABuGh5O0saJ2mqpKmdnQtqEWfupGU7aUeUvUmQmeWpZdXBbDz+B8w87VI65y8sOpyG4vfkvokaTkXImox0pD/3Ai6KiEnAwOXtHBHjI2K7iNiupeVDKxtjXcxqn836I4e/vzxyxDBmz36twIjMrD/TgFY2Hv8D3rr2Lt65+YGiw2k4fk/um2ZpMzJL0sXAgcBNkgb14dhSmDL1MTbZZDSjRq1PW1sbBx64H9ffcGvRYZlZP7XhOUex6IV2XrtkctGhNCS/JzeXrOOMHAjsCZwTEe9IGgackF9Y9dfR0cGxx53MTTf+jtaWFq6YcDXTprkOuNaOuOA4Nt1hC1Zbawjn3H8xk867mnsm3l50WA3F1zh/q43djKEH7Mq7019m81vOA2DWWb9lzu0PFxxZ4/B7ct+UfdAzZa2Dk9QKfISKBCYiXql23ICBI8p9hUrgm8N3LDoEsyMqGpoAABVASURBVJo4cunSokNoeDu8PqXoEJrC0vdm1fVpMd8f9bWafdae9/Lv6/6km0wlI5KOBk4FXuODKqUAPp5TXGZmZtYkslbTHAtsGhFv5hmMmZmZ9V1RDU9rJWsyMhOYk2cgZmZmtmKi5G1Gek1GJB2fzs4A7pR0I7C4a3tE+OEXZmZmtlKqlYwMSX++kk4D6WV8ETMzM6u/hq6miYjT6xWImZmZrZiyd+3N2pvmepYdJXYOMBW4OCIW1TowMzMzaw5ZR1GdAcwHLkmnuSTdfD+aLpuZmVlByv5smqy9abaJiJ0rlq+XdHdE7Czp6TwCMzMzs2zKXk2TtWRkHUkbdC2k80PTxfdqHpWZmZk1jawlI/8O3CvpRUDAaOBISR8CJuQVnJmZmVXX0L1pukTETZLGAB8jSUaeqWi0+rO8gjMzM7Pq6jnomaTLgL2B1yNiyx62Czgf+CLwLnBoRDzS2zmz9qb5ZrdVH5dERFyZKXIzMzNrFFcAFwLLywG+AIxJp08BF6U/lytrNc3YivnBwG7AI70EYmZmZnVSz2qaiLhb0qhedtkPuDIiAnhA0pqShkXE7OUdkLWa5ujKZUlrAL/JcqyZmZnlq5bVNJLGAeMqVo2PiPF9OMUIkmfadWlP161cMtKDd0mKX8zMzKyBpIlHX5KP7tTTaXs7YEVGYG0FNgMm9ik0MzMzy0U/603TDqxfsTwSeLW3A7KWjJxTMb8U+HtEtPctNjMzM8tDZ/SrQc8mA0dJ+j1Jw9U5vbUXgextRu6S9BE+aMj6/EqFaWZmZqUk6SpgF2CopHbgVKANICJ+BdxE0q33BZJmHYdVO2fWapoDgZ8Cd5LUBf1c0gkRcU2f/xdmZmZWU/UsF4mIr1fZHsD3+nLOrNU0/wWMjYjXASStA/wVcDJiZmZWsGZ5Nk1LVyKSerMPx5qZmZktV9aSkT9LugW4Kl0+iKROyMzMzApWz+Hg85C1AesJkr4C7ETSZmR8RFyba2RmZmaWST/r2ttnVZMRSa3ALRHxeeBP+YdkZmZmzaRqMhIRHZLelbRGRMypR1BmZmaWXdkbsGZtM7IIeFLSX4AFXSsj4phcojIzM7PMmqLNCHBjOpmZmZnVVNY2I/8SEQfXIR4zMzPro4ZvwJq2GVlH0sCIeK8eQZmZmVl20b+eTdNnWatpXgbukzSZf24zcm4eQZmZmVnzyJqMvJpOLcCQ/MIxMzOzvmqK3jQRcXregZj1Z1e+en/RITSFK4sOoAnMPXP3okOwHDR8mxEASXfQw0MBI+JzNY/IzMzM+qRZuvb+R8X8YGB/YGntwzEzM7Nmk7Wa5uFuq+6TdFcO8ZiZmVkfNUWbEUlrVyy2ANsB6+USkZmZmfVJs3TtfZgP2owsJenqe3geAZmZmVlzyZqMbA4cCexEkpTcA0zNKygzMzPLril60wATgLnABeny14HfAF/NIygzMzPLrll602waEVtXLN8h6fE8AjIzM7Pm0pJxv0cl7dC1IOlTwH35hGRmZmZ90UnUbCpCryUjkp4kaSPSBnxT0ivp8obAtPzDMzMzs2oavTfN3nWJwszMzJpWr8lIRPy9XoGYmZnZimmKQc/MzMys/yp7b5qsDVjNzMzMcuGSETMzs5LrbPAGrGZmZtbPlTsVcTWNmZmZFcwlI2ZmZiXn3jRmZmZWqLInI66mMTMzs0K5ZMTMzKzkGn04eDMzM+vnXE1jZmZmthJcMmJmZlZyZR8O3smImZlZyZW9zYiraczMzCwzSXtKelbSC5L+s4fth0r6h6TH0unb1c7pkhEzM7OSq1cDVkmtwC+AfwHagSmSJkfEtG67Xh0RR2U9r5MRMzOzkqtjNc32wAsRMQNA0u+B/YDuyUifuJrGzMzM3idpnKSpFdO4is0jgJkVy+3puu72l/SEpGskrV/tNV0yYmZmVnK1rKaJiPHA+OVsVk+HdFu+HrgqIhZL+g4wAfhcb6/pkhEzM7OSixr+q6IdqCzpGAm8+k+xRLwZEYvTxUuAbaud1MmImZmZZTUFGCNptKSBwNeAyZU7SBpWsbgvML3aSV1NY2ZmVnKddWrAGhFLJR0F3AK0ApdFxNOSzgCmRsRk4BhJ+wJLgbeAQ6ud18mImZlZydVzBNaIuAm4qdu6UyrmTwJO6ss5XU1TYY/dd+Hpp+7mmWn3cuIJ3ys6nIZ02NlH8rOpl3LGLecWHUpD872cP1/jOmgdwKB//RGDDzudwYf/mLadvlR0RJYTJyOplpYWLjj/J+y9z8FstfWuHHTQl9hsszFFh9Vw7rvmDs495MdFh9HQfC/nz9e4TjqWsvj3Z7Po8lNZdPmptIzekpbhGxUdVb/UGVGzqQhORlLbj92GF198mZdeeoUlS5YwceIk9t1nj6LDajjPPTSdBXPmFx1GQ/O9nD9f4zpaknbKaGlFLQOW7URqQF170+QiUzKixMGSTkmXN5C0fb6h1dfwEesxs/2D3knts2YzfPh6BUZktmJ8L+fP17iOJAYfejqrHH0+HS8/TefsGUVHZDnI2oD1l0AnyaAlZwDzgD8CY3vaOR2tbRyAWtegpeVDKx9pzqRlx3Ep+1MQrTn5Xs6fr3EdRbDoilNh0CoM+vLRaOgI4o1ZRUfV7xRVvVIrWatpPhUR3wMWAUTE28DA5e0cEeMjYruI2K4MiQjArPbZrD9y+PvLI0cMY/bs1wqMyGzF+F7On69xARYvpGPms7RutFXRkfRLTVFNAyxJn9QXAJLWISkpaRhTpj7GJpuMZtSo9Wlra+PAA/fj+htuLTossz7zvZw/X+M6WWUIDFolmR/QRuuGm9P55uxiY7JcZK2muQC4FlhX0k+AA4CTc4uqAB0dHRx73MncdOPvaG1p4YoJVzNt2nNFh9VwjrjgODbdYQtWW2sI59x/MZPOu5p7Jt5edFgNxfdy/nyN60OrrcGgvb4NagGJpc9MofPFx4sOq18qezWNstZzSvoYsBvJQ3Jui4iqw7sCDBg4otxXqAS+OXzHokNoeFe+en/RIZjVxNwzdy86hKaw6g8u7+mBcrnZaOg2NfusnfHGo3WNHaqUjEhau2LxdeCqym0R8VZegZmZmVlzqFZN8zBJO5GuLKkr81I679FnzMzMChZR7macvSYjETG6XoGYmZnZiuks+WhwWQc9uy3LOjMzM7O+qtZmZDDwIWCopLX4oLpmdWD4cg80MzOzuin7oHvV2owcARxHkng8UrF+LvCLvIIyMzOz7MpeTVOtzcj5wPmSjo6In9cpJjMzM2siWQc9u1jSMcDO6fKdwMURsSSXqMzMzCyzRq+m6fJLoC39CfCvwEXAt/MIyszMzLIr+wisWZORsRGxdcXy7ZI8Jq+ZmZmttKwPyuuQtHHXgqSNgI58QjIzM7O+KPtTe7OWjJwA3CFpBkn33g2Bb+UWlZmZmWXWLG1G7gXGAJuSJCPP5BaRmZmZ9UnZu/Zmraa5PyIWR8QTEfF4RCwG/BhTMzMzW2nVRmBdDxgBrCJpG/55BNZVc47NzMzMMmj0apo9gEOBkcD/44NkZB7ww/zCMjMzs6waumtvREwAJkjaPyL+WKeYzMzMrIlkbTMyUtLqSvxa0iOSds81MjMzM8skImo2FSFrMvKtiJgL7A6sCxwG/N/cojIzM7PMOomaTUXImox0tRX5InB5RDxesc7MzMxshWUdZ+RhSbcCo4GTJA0BOvMLy8zMzLJq9N40XQ4HPgHMiIh3JX2YpKrGzMzMCtbQvWkkfSwiniFJRAA2klw7Y2ZmZrVTrWTkeGAcyRgj3QXwuZpHZGZmZn1S1APuaqXaOCPjJLUAJ0fEfXWKyczMzPqg7NU0VXvTREQncE4dYjEzM7MmlLVr762S9pcbjJiZmfU7ZR/0LGtvmuOBDwFLJS0iGWMkImL13CIzMzOzTBq6zUiXiBgiaW1gDDA435DMzMysmWRKRiR9GziW5Om9jwE7AH8DdssvNDMzM8ui7IOeZW0zciwwFvh7ROwKbAO8kVtUZmZmllk924xI2lPSs5JekPSfPWwfJOnqdPuDkkZVO2fWZGRRRCzqepF0ILRNMx5rZmZmDUBSK/AL4AvA5sDXJW3ebbfDgbcjYhPgPOCsaufNmoy0S1oTuA74i6RJwKtZgzczM7P8RA2nKrYHXoiIGRHxHvB7YL9u++wHTEjnrwF2q9YbN2sD1i+ns6dJugNYA/hzlmOXvjerdN2BJY2LiPFFx9HIynaNLys6gBVQtmtcVr7O+fM1rq6Wn7WSxpGMvt5lfMX1HwHMrNjWDnyq2yne3ycilkqaA3yYXpp3ZC0ZeV9E3BURk9OMqFGNq76LrSRf4/z5GteHr3P+fI3rKCLGR8R2FVNlIthT0tO9QCXLPv+kz8mImZmZNa12YP2K5ZEs22zj/X0kDSCpTXmrt5M6GTEzM7OspgBjJI2WNBD4GjC52z6TgUPS+QOA26NKN52sI7A2G9dN5s/XOH++xvXh65w/X+N+Im0DchRwC9AKXBYRT0s6A5gaEZOBS4HfSHqBpETka9XOq7IPlGJmZmbl5moaMzMzK5STETMzMyuUkxH7J5JGSXqqhufbRdKnK5avkHRArc7fDCSdJuk/JJ0h6fO97HeopAvrGVt/V+v7uZa6fq9Fx1EkSb/uYfTOyu2HShqe4TzHSVq1YvllSUNrFaflz8lIFenQt7bidgE+XW2nLJr9dxERp0TEX4uOo1mkXRKXu2wrR1JrRHw7Iqb1stuhQNVkBDgOWLXqXtZvNUQyIulgSQ9JekzSxZJaJc2XdJakhyX9VdL2ku6UNEPSvulxrZJ+KmmKpCckHZGu30XSHZJ+Bzwp6UOSbpT0uKSnJB2U7rebpEclPSnpMkmD0vUvSzpd0iPpto8VdnFWTKukSyQ9LelWSatI+rf0Oj0u6Y+SVk2v3wwl1pTUKWlnAEn3SNoE+A7w/fR389n0/DtL+lt67AHp/kp/F0+l16zrGnf/XYySNL17fOm+G0v6c/o7v6eE1/19kv5LyYOo/kr6HKjKUiVJY9Nr+Hh67w/pdvxeku6XNFTSOunvbEo6fSbd57T0vu36uzgmXd/j/V5iAyRNSP/Gr0nv3fe/OUvaTtKd6fxpksZLuhW4Usk38z9Iuh64tcp9ekPXC0q6UNKh6fwXJT0j6V5JF1TuB2zeqNdf0nXp3+LTSkb0RMn78hmSHgR2TP/v26XvJVdUXNfvp/f6dsD/pO8fq6iH99z0ug0H7lAyQnj3OJb5fKjrhbBsavmkvyImYDPgeqAtXf4l8E2S0d6+kK67FrgVaAO2Bh5L148DTk7nBwFTgdEk3+YXAKPTbfsDl1S85hrAYJLhbj+arrsSOC6dfxk4Op0/Evh10depD9dzFLAU+ES6PBE4GPhwxT4/rvj//RnYAtibpP/5f6XX8qV0+2nAf1QcewXwB5JEeHOSZxx0XeO/kHQV+wjwCjCsh99Fj/Gl87cBY9L5T5H0bS/8mq7A72Bb4EmSb3qrAy8A/5FeuwOAgcAMYGy6/+ok3fQPBS4EvgzcA6yVbv8dsFM6vwEwveJ387f09zUUeDP9G1nmfi/6mqzk/RzAZ9Lly9Jr+TIwNF23HXBnxTV5GFglXT6UZACntTPcpzdUvO6F6bFd7xNd9+9VXfs1+vWvuGarAE+RDAcewIEV+9yZXv9tgb9UrF+zcns6X+09d2jF8S+n17THz4eir42nZadGKBnZjeRGniLpsXR5I+A9Pnh+zpPAXRGxJJ0fla7fHfhmetyDJH8sY9JtD0XESxXHf15JSctnI2IOybfVlyLiuXSfCcDOFXH9Kf35cMXrlcVLEfFYOt8V/5ZpacOTwDdIEhBIPvR2Tqf/BnYCxpIkJstzXUR0RlI8+5F03U7AVRHRERGvAXel54F//l30GJ+k1Uiqg/6Q/j4vJvmQKKPPAtdGxLsRMZdlBxTaFJgdEVMAImJuRCxNt+0K/ADYKyLeTtd9HrgwvS6TgdUrSlJujIjFEfEG8DrJ76On+73MZkbEfen8b0nutd5MjoiFFct/iYiu0SN7u0978jFgRsX9e1W37Y18/Y+R9DjwAMlonGOADuCPPew7A9hI0s8l7QnM7WGfau+5PVne54P1M42QjAiYEBGfSKdNI+I0YElEdA2i0gksBoiITj4Y7E0k3/C7jh0dEbem2xZ0vUB683d9W/1vSafQ89j7lRanPzso3+Byiyvmu+K/AjgqIrYCTif5lgJJMvJZkic53gSsSfIt8e6M51e3nz1Z0G25p/hagHcqfpefiIjNejlnf9fbAEDqZfsMYAjw0Yp1LcCOFddlRETMS7ctcy2Xc7+XWfdrFSSla13vf4O7be9+v1UuL+8+rTxf5Tmzvk9AA11/SbuQJME7RsTWwKMk12RRRHR03z9NnLcmKQn5HvDrnk67IqHQ8+eD9TONkIzcBhwgaV0ASWtL2jDjsbcA35XUlh77UUkf6r6Tktbc70bEb4FzgE8Cz5B8I98k3e1fSb4lNaohwOz0Wn2jYv2DJCUSnRGxCHgMOIIkSQGYlx5bzd3AQWnd8Tok33geyhpcWoLwkqSvwvttULbOenw/czfw5bSOfAiwT7ftzwDDJY0FkDREHzSu/DvwFZL2Dl2lV7cCR3UdLOkTvb34cu73MttA0o7p/NeBe0mK8bdN1+3fh3Mt7z79O0n7j0GS1iD5Bg7J72ojSaPS5artPxrk+q8BvB0R7yppu7VDbzun7XdaIuKPwI/44P9c+f7R23vu8t5nVubzweqobN/YlxER0ySdTNK4rAVYQpJZZ/FrkiqIRyQJ+AfwpR722wr4qaTO9PzfjYhFkg4jqRYYQFIt8auV+9/0az8iSTz+TvKNbQhARCyWNJOkKBaSJOTr6T6Q1NdeI2k/4Ohezn8tsCPwOMk31xMj4n/Vt0ao3wAuSu+HNuD36flKJSIekXQ1SWL3dz5I7Lq2v5c2avy5ksa7C0m+hXZtf1bSN0juzX2AY4BfSHqC5G/+bpKGxcuzzP1eu/9dIaYDh0i6GHgeuIgkgbhU0g9J7uuserxPASRNBJ5IX+NRgIhYKOlI4M+S3iBbgt0I1//PwHfSe+5ZPnh/WJ4RwOXpezjASenPK4BfSVpIct2X9547HrhZ0uyI2LXrpL18Pvx9Zf+DVlseDt7MLEeSVouI+ekXnl8Az0fEeUXHZdafNEI1jZlZf/ZvaePJp0mqLy4uOB6zfsclI2ZmZlYol4yYmZlZoZyMmJmZWaGcjJiZmVmhnIyYmZlZoZyMmJmZWaH+f4Ov37ggxbhfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrice_de_confusion(modele1.matrice_labels_test, y_pred_knn, modele1.auteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont peu satisfaisants: sur 30 textes, seuls $2 + 3 + 1 + 3 + 3 = 12$ textes sont identifiés correctement. K-NN ne semble donc pas un bon algorithme pour mes données (certainement car la dimention d'attributs est très grande)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va donc essayer l'algorithme Random Forrest Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tree Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forrest Tree n'est pas aussi simple à implémenter, vu qu'il a besoin de labels numériques: les prédictions qu'il va donner ne seront pas discrètes, il faudra donc arrondir chacune des prévisions à l'entier le plus proche, et on peut obtenir la prédiction d'auteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatation des labels pour Random Forrest Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit une fonction qui transforme le nom des auteurs en des entiers ordonnés. Ces entiers dépendent du nombre d'auteurs, mais pour 5 auteurs (notre cas), on a des entiers de 0 à 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def labels_random_forrest(labels, auteurs):\n",
    "    label_random_forrest = []\n",
    "    for label in labels:\n",
    "        for auteur in auteurs:\n",
    "            if label == auteur:\n",
    "                label_random_forrest.append(auteurs.index(auteur))\n",
    "    return np.array(label_random_forrest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'emerson'),\n",
       " (1, 'hawthorne'),\n",
       " (2, 'dickens'),\n",
       " (3, 'burroughs'),\n",
       " (4, 'aristotle')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in enumerate(modele1.auteurs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec cette fonctrion on peut donc transformer les labels d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rf_train_labels = labels_random_forrest(modele1.matrice_labels_train, modele1.auteurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_labels = labels_random_forrest(modele1.matrice_labels_test, modele1.auteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant construire le classificateur Random Forrest. On crée une fonction qui simplifie cette tâche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def random_forrest(estimateur, features, labels):\n",
    "    regressor = RandomForestRegressor(n_estimators=estimateur, random_state=0)\n",
    "    regressor.fit(features, labels)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le choix du nombre d'estimateurs est un hyperparamètre à choisir. Après avoir testé plusieurs, 1500 semble obtenir la meilleure sollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "regressor = random_forrest(1500, modele1.matrice_features_train, rf_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme mentionné précédemment, il faut maintenant arrondir les prédictions de Random Forrest Tree. On utilise la fonction suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_predict(regressor, test_features):\n",
    "    y_prob = regressor.predict(test_features)\n",
    "    \n",
    "    y_pred = []\n",
    "    for prob in y_prob:\n",
    "        y_pred.append(round(prob))\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_predict(regressor, modele1.matrice_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir visualiser la performance de la prédiction, on construit la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff3f836f310>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrice_de_confusion(rf_test_labels, y_pred_rf, modele1.auteurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que sur 30 textes testés, il y a $1 + 1 + 1 + 1 + 2 = 6$ textes mal classifiés. Cet algorihtme a une précision de 80%, ce qui est un résultat plutôt très satisfaisant. (beaucoup mieux que K-NN).\n",
    "\n",
    "Avec uniquement des métriques de style, récupérables sur n'importe quel texte, notre algorithme a réussi à identifier avec une précision de 80% les auteurs des textes. Cela est un bon résultat, si on prend en compte que chaque auteur peut ne pas écrire tout le temps avec le même style. \n",
    "\n",
    "J'ai choisit les données de façon plus ou moins aléatoire, mais pour avoir de meilleurs résultats, il faudrait trouver une base de données plus consistente, qui soit représentative des différents styles d'un seul auteur. Mais c'est déjà un pas :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "final.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
